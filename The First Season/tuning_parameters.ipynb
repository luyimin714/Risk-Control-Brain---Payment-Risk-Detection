{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "# 作者：wanglei5205\n",
    "# 邮箱：wanglei5205@126.com\n",
    "# 博客：http://cnblogs.com/wanglei5205\n",
    "# github：http://github.com/wanglei5205\n",
    "\"\"\"\n",
    "### 导入模块\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "\n",
    "### 载入数据\n",
    "print('载入数据')\n",
    "dataset1 = pd.read_csv('G:/ML/ML_match/IJCAI/data3.22/3.22ICJAI/data/7_train_data1.csv')\n",
    "dataset2 = pd.read_csv('G:/ML/ML_match/IJCAI/data3.22/3.22ICJAI/data/7_train_data2.csv')\n",
    "dataset3 = pd.read_csv('G:/ML/ML_match/IJCAI/data3.22/3.22ICJAI/data/7_train_data3.csv')\n",
    "dataset4 = pd.read_csv('G:/ML/ML_match/IJCAI/data3.22/3.22ICJAI/data/7_train_data4.csv')\n",
    "dataset5 = pd.read_csv('G:/ML/ML_match/IJCAI/data3.22/3.22ICJAI/data/7_train_data5.csv')\n",
    "\n",
    "print('数据去重')\n",
    "dataset1.drop_duplicates(inplace=True)\n",
    "dataset2.drop_duplicates(inplace=True)\n",
    "dataset3.drop_duplicates(inplace=True)\n",
    "dataset4.drop_duplicates(inplace=True)\n",
    "dataset5.drop_duplicates(inplace=True)\n",
    "\n",
    "print('数据合并')\n",
    "trains = pd.concat([dataset1,dataset2],axis=0)\n",
    "trains = pd.concat([trains,dataset3],axis=0)\n",
    "trains = pd.concat([trains,dataset4],axis=0)\n",
    "\n",
    "online_test = dataset5\n",
    "\n",
    "### 数据拆分(训练集+验证集+测试集)\n",
    "print('数据拆分')\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_xy,offline_test = train_test_split(trains,test_size = 0.2,random_state=21)\n",
    "train,val = train_test_split(train_xy,test_size = 0.2,random_state=21)\n",
    "\n",
    "# 训练集\n",
    "y_train = train.is_trade                                               # 训练集标签\n",
    "X_train = train.drop(['instance_id','is_trade'],axis=1)                # 训练集特征矩阵\n",
    "\n",
    "# 验证集\n",
    "y_val = val.is_trade                                                   # 验证集标签\n",
    "X_val = val.drop(['instance_id','is_trade'],axis=1)                    # 验证集特征矩阵\n",
    "\n",
    "# 测试集\n",
    "offline_test_X = offline_test.drop(['instance_id','is_trade'],axis=1)  # 线下测试特征矩阵\n",
    "online_test_X  = online_test.drop(['instance_id'],axis=1)              # 线上测试特征矩阵\n",
    "\n",
    "### 数据转换\n",
    "print('数据转换')\n",
    "lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train,free_raw_data=False)\n",
    "\n",
    "### 设置初始参数--不含交叉验证参数\n",
    "print('设置参数')\n",
    "params = {\n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'binary',\n",
    "          'metric': {'binary_logloss', 'auc'},\n",
    "          }\n",
    "\n",
    "### 交叉验证(调参)\n",
    "print('交叉验证')\n",
    "min_merror = float('Inf')\n",
    "best_params = {}\n",
    "\n",
    "# 准确率\n",
    "print(\"调参1：提高准确率\")\n",
    "for num_leaves in range(20,200,5):\n",
    "    for max_depth in range(3,8,1):\n",
    "        params['num_leaves'] = num_leaves\n",
    "        params['max_depth'] = max_depth\n",
    "\n",
    "        cv_results = lgb.cv(\n",
    "                            params,\n",
    "                            lgb_train,\n",
    "                            seed=2018,\n",
    "                            nfold=3,\n",
    "                            metrics=['binary_error'],\n",
    "                            early_stopping_rounds=10,\n",
    "                            verbose_eval=True\n",
    "                            )\n",
    "\n",
    "        mean_merror = pd.Series(cv_results['binary_error-mean']).min()\n",
    "        boost_rounds = pd.Series(cv_results['binary_error-mean']).argmin()\n",
    "\n",
    "        if mean_merror < min_merror:\n",
    "            min_merror = mean_merror\n",
    "            best_params['num_leaves'] = num_leaves\n",
    "            best_params['max_depth'] = max_depth\n",
    "\n",
    "params['num_leaves'] = best_params['num_leaves']\n",
    "params['max_depth'] = best_params['max_depth']\n",
    "\n",
    "# 过拟合\n",
    "print(\"调参2：降低过拟合\")\n",
    "for max_bin in range(1,255,5):\n",
    "    for min_data_in_leaf in range(10,200,5):\n",
    "            params['max_bin'] = max_bin\n",
    "            params['min_data_in_leaf'] = min_data_in_leaf\n",
    "\n",
    "            cv_results = lgb.cv(\n",
    "                                params,\n",
    "                                lgb_train,\n",
    "                                seed=42,\n",
    "                                nfold=3,\n",
    "                                metrics=['binary_error'],\n",
    "                                early_stopping_rounds=3,\n",
    "                                verbose_eval=True\n",
    "                                )\n",
    "\n",
    "            mean_merror = pd.Series(cv_results['binary_error-mean']).min()\n",
    "            boost_rounds = pd.Series(cv_results['binary_error-mean']).argmin()\n",
    "\n",
    "            if mean_merror < min_merror:\n",
    "                min_merror = mean_merror\n",
    "                best_params['max_bin']= max_bin\n",
    "                best_params['min_data_in_leaf'] = min_data_in_leaf\n",
    "\n",
    "params['min_data_in_leaf'] = best_params['min_data_in_leaf']\n",
    "params['max_bin'] = best_params['max_bin']\n",
    "\n",
    "print(\"调参3：降低过拟合\")\n",
    "for feature_fraction in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "    for bagging_fraction in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "        for bagging_freq in range(0,50,5):\n",
    "            params['feature_fraction'] = feature_fraction\n",
    "            params['bagging_fraction'] = bagging_fraction\n",
    "            params['bagging_freq'] = bagging_freq\n",
    "\n",
    "            cv_results = lgb.cv(\n",
    "                                params,\n",
    "                                lgb_train,\n",
    "                                seed=42,\n",
    "                                nfold=3,\n",
    "                                metrics=['binary_error'],\n",
    "                                early_stopping_rounds=3,\n",
    "                                verbose_eval=True\n",
    "                                )\n",
    "\n",
    "            mean_merror = pd.Series(cv_results['binary_error-mean']).min()\n",
    "            boost_rounds = pd.Series(cv_results['binary_error-mean']).argmin()\n",
    "\n",
    "            if mean_merror < min_merror:\n",
    "                min_merror = mean_merror\n",
    "                best_params['feature_fraction'] = feature_fraction\n",
    "                best_params['bagging_fraction'] = bagging_fraction\n",
    "                best_params['bagging_freq'] = bagging_freq\n",
    "\n",
    "params['feature_fraction'] = best_params['feature_fraction']\n",
    "params['bagging_fraction'] = best_params['bagging_fraction']\n",
    "params['bagging_freq'] = best_params['bagging_freq']\n",
    "\n",
    "print(\"调参4：降低过拟合\")\n",
    "for lambda_l1 in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "    for lambda_l2 in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "        for min_split_gain in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "            params['lambda_l1'] = lambda_l1\n",
    "            params['lambda_l2'] = lambda_l2\n",
    "            params['min_split_gain'] = min_split_gain\n",
    "\n",
    "            cv_results = lgb.cv(\n",
    "                                params,\n",
    "                                lgb_train,\n",
    "                                seed=42,\n",
    "                                nfold=3,\n",
    "                                metrics=['binary_error'],\n",
    "                                early_stopping_rounds=3,\n",
    "                                verbose_eval=True\n",
    "                                )\n",
    "\n",
    "            mean_merror = pd.Series(cv_results['binary_error-mean']).min()\n",
    "            boost_rounds = pd.Series(cv_results['binary_error-mean']).argmin()\n",
    "\n",
    "            if mean_merror < min_merror:\n",
    "                min_merror = mean_merror\n",
    "                best_params['lambda_l1'] = lambda_l1\n",
    "                best_params['lambda_l2'] = lambda_l2\n",
    "                best_params['min_split_gain'] = min_split_gain\n",
    "\n",
    "params['lambda_l1'] = best_params['lambda_l1']\n",
    "params['lambda_l2'] = best_params['lambda_l2']\n",
    "params['min_split_gain'] = best_params['min_split_gain']\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "\n",
    "### 训练\n",
    "params['learning_rate']=0.01\n",
    "lgb.train(\n",
    "          params,                     # 参数字典\n",
    "          lgb_train,                  # 训练集\n",
    "          valid_sets=lgb_eval,        # 验证集\n",
    "          num_boost_round=2000,       # 迭代次数\n",
    "          early_stopping_rounds=50    # 早停次数\n",
    "          )\n",
    "\n",
    "### 线下预测\n",
    "print (\"线下预测\")\n",
    "preds_offline = lgb.predict(offline_test_X, num_iteration=lgb.best_iteration) # 输出概率\n",
    "offline=offline_test[['instance_id','is_trade']]\n",
    "offline['preds']=preds_offline\n",
    "offline.is_trade = offline['is_trade'].astype(np.float64)\n",
    "print('log_loss', metrics.log_loss(offline.is_trade, offline.preds))\n",
    "\n",
    "### 线上预测\n",
    "print(\"线上预测\")\n",
    "preds_online =  lgb.predict(online_test_X, num_iteration=lgb.best_iteration)  # 输出概率\n",
    "online=online_test[['instance_id']]\n",
    "online['preds']=preds_online\n",
    "online.rename(columns={'preds':'predicted_score'},inplace=True)           # 更改列名\n",
    "online.to_csv(\"./data/20180405.txt\",index=None,sep=' ')                   # 保存结果\n",
    "\n",
    "### 保存模型\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(lgb,'lgb.pkl')\n",
    "\n",
    "### 特征选择\n",
    "df = pd.DataFrame(X_train.columns.tolist(), columns=['feature'])\n",
    "df['importance']=list(lgb.feature_importance())                           # 特征分数\n",
    "df = df.sort_values(by='importance',ascending=False)                      # 特征排序\n",
    "df.to_csv(\"./data/feature_score_20180331.csv\",index=None,encoding='gbk')  # 保存分数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
